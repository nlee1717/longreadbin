{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from functools import partial\n",
    "# author: Hari S. Muralidharan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qualify_Alignments(row, contain = 0.95, overhang_cutoff = 100):\n",
    "    if ((row['Overhang'] > overhang_cutoff) and (row['Overhang']/row['AlignLength'] > 0.1) and \n",
    "        (row['AlignLength']/min(row['QLen'], row['SLen']) < contain)):\n",
    "        return \"Internal_Match\"\n",
    "    \n",
    "    elif ((row['QStart'] <= row['SStart']) and  \n",
    "          (row['AlignLength']/min(row['QLen'], row['SLen']) >= contain)):\n",
    "        return \"q in s\"\n",
    "    \n",
    "    elif ((row['QStart'] >= row['SStart']) and \n",
    "          (row['AlignLength']/min(row['QLen'], row['SLen']) >= contain)):\n",
    "        return \"s in q\"\n",
    "    \n",
    "    elif row['QStart'] > row['SStart']:\n",
    "        return \"q overlaps s\"\n",
    "    \n",
    "    else:\n",
    "        return \"s overlaps q\"\n",
    "\n",
    "def Build_Graph(df_Containments):\n",
    "    edge_list = list(zip(df_Containments['Query'].tolist(), df_Containments['Subject'].tolist()))\n",
    "    G = nx.DiGraph(edge_list)\n",
    "    nodes = df_Containments['Query'].tolist()+df_Containments['Subject'].tolist()\n",
    "   \n",
    "    d_length = dict(zip(nodes, df_Containments['QLen'].tolist()+df_Containments['SLen'].tolist()))\n",
    "    nx.set_node_attributes(G, d_length, name=\"length\")\n",
    "\n",
    "    d_edgetype = dict(zip(edge_list, df_Containments['Alignment_Type'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_edgetype, name=\"type\")\n",
    "\n",
    "    d_qcov = dict(zip(edge_list, df_Containments['QCov'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_qcov, name=\"qcov\")\n",
    "\n",
    "    d_scov = dict(zip(edge_list, df_Containments['SCov'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_scov, name=\"scov\")\n",
    "\n",
    "    d_qstart = dict(zip(edge_list, df_Containments['QStart'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_qstart, name=\"qstart\")\n",
    "\n",
    "    d_qend = dict(zip(edge_list, df_Containments['QEnd'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_qend, name=\"qend\")\n",
    "\n",
    "    d_sstart = dict(zip(edge_list, df_Containments['SStart'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_sstart, name=\"sstart\")\n",
    "\n",
    "    d_send = dict(zip(edge_list, df_Containments['SEnd'].tolist()))\n",
    "    nx.set_edge_attributes(G, d_send, name=\"send\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "def Simplify_Containment_Clusters(g, cluster_id):\n",
    "    containment_clusters = []\n",
    "    d_lengths = nx.get_node_attributes(g, \"length\")\n",
    "    nodes, lengths = np.array(list(d_lengths.keys())), np.array(list(d_lengths.values()))\n",
    "    nodes_sorted = nodes[np.argsort(lengths)[::-1]]\n",
    "    \n",
    "    visited = set({})\n",
    "    \n",
    "    for n in nodes_sorted:\n",
    "        if n not in visited:\n",
    "            cluster = [n] + list(g.neighbors(n))\n",
    "            op = []\n",
    "            for c in cluster[1:]:\n",
    "                d = {'RepresentativeContig':n, 'Contig':c, 'EdgeType':g.edges[(n,c)]['type'], \n",
    "                     'RepresentativeLength':g.nodes[n]['length'], 'ContigLength':g.nodes[c]['length'],\n",
    "                     'qstart':g.edges[(n,c)]['qstart'], 'qend':g.edges[(n,c)]['qend'], \n",
    "                     'sstart':g.edges[(n,c)]['sstart'], 'send':g.edges[(n,c)]['send'],\n",
    "                     'Cluster_ID':cluster_id}\n",
    "                op.append(d)\n",
    "            cluster_id += 1\n",
    "            g.remove_nodes_from(cluster)\n",
    "            visited.update(cluster)\n",
    "            if len(cluster) > 1:\n",
    "                containment_clusters+= op\n",
    "    return containment_clusters\n",
    "\n",
    "def Load_PAF(filepath):\n",
    "    header = ['Query','QLen','QStart','QEnd','Orientation','Subject',\n",
    "              'SLen','SStart','SEnd','Matches','AlignLength','MAPQ']\n",
    "    op = []\n",
    "    with open(filepath) as fileobject:\n",
    "        for l in fileobject:\n",
    "            l = l.split('\\t')[:12]\n",
    "            op.append(dict(zip(header, l)))\n",
    "    df = pd.DataFrame(op)\n",
    "    df[['QLen','QStart','QEnd','SLen','SStart',\n",
    "        'SEnd','Matches','AlignLength','MAPQ']] = df[['QLen','QStart','QEnd','SLen','SStart',\n",
    "                                                      'SEnd','Matches','AlignLength','MAPQ']].astype('int')\n",
    "    df['PIdent'] = df['Matches']/df['AlignLength']*100\n",
    "    df['QCov'] = df['AlignLength']/df['QLen']*100\n",
    "    df['SCov'] = df['AlignLength']/df['SLen']*100\n",
    "    df['Overhang'] = (np.minimum(df['SStart'],df['QStart']) + np.minimum(df['QLen']-df['QEnd'], \n",
    "                                                                         df['SLen']-df['SEnd']))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/harihara/Mount/Phage-Detection/Potential_Phages_Updated/Minimap2_Alignments.paf'\n",
    "df = Load_PAF(data_path)\n",
    "df = df[df['Query'] != df['Subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77949"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['Query'].tolist()) | set(df['Subject'].tolist())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_identity_cutoff = 70\n",
    "containment_cutoff = 0.80\n",
    "overhang_cutoff = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.loc[df['PIdent'] >= percent_identity_cutoff, :].copy()\n",
    "df_filtered = df_filtered.loc[df_filtered.groupby(['Query','Subject'])['AlignLength'].idxmax()]\n",
    "df_filtered.loc[:,'Alignment_Type'] = df_filtered.apply(partial(Qualify_Alignments, \n",
    "                                                                contain = containment_cutoff,\n",
    "                                                                overhang_cutoff = overhang_cutoff), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Containments = df_filtered.loc[(df_filtered['Alignment_Type'] == 'q in s')|\n",
    "                                  (df_filtered['Alignment_Type'] == 's in q'), :].copy()\n",
    "G = Build_Graph(df_Containments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = list(nx.weakly_connected_components(G))\n",
    "containment_clusters = []\n",
    "cluster_id = 0\n",
    "for c in conn:\n",
    "    g = nx.Graph(G.subgraph(c))\n",
    "    clusters = Simplify_Containment_Clusters(g, cluster_id)\n",
    "    if len(clusters) > 1: cluster_id = clusters[-1]['Cluster_ID']+1\n",
    "    containment_clusters += clusters\n",
    "df_containment_clusters = pd.DataFrame(containment_clusters)\n",
    "df_containment_clusters.to_csv('Phage_Clusters.txt', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
